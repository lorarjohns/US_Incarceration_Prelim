# Load in and clean second dataset
# This dataset includes number of persons incarcerated
# by other adult correctional systems, 2000, 2010, and 2015-2016
# Please note, columns '2000', '2010', '2015', '2016' are in total persons;
# columns 'Average annual change, 2000-2015' and 'Percent change, 2015-2016' and in %

df2 = pd.read_csv('cpus16at02.csv', encoding ='latin1', skiprows=10, header=1)
df2["Other adult correctional systems"] = df2["Other adult correctional systems"].map(str) + df2["Unnamed: 1"].map(str)
df2["Other adult correctional systems"] = df2["Other adult correctional systems"].str.replace("nan", "").replace("NaN", "")
df2 = df2[df2.columns.drop(list(df2.filter(regex='Unnamed:')))]
df2.drop(df2.tail(5).index,inplace=True)

# Load in and clean second dataset
# This dataset includes number of persons incarcerated
# by other adult correctional systems, 2000, 2010, and 2015-2016
# Please note, columns '2000', '2010', '2015', '2016' are in total persons;
# columns 'Average annual change, 2000-2015' and 'Percent change, 2015-2016' and in %

df2 = pd.read_csv('cpus16at02.csv', encoding ='latin1', skiprows=10, header=1)
df2["Other adult correctional systems"] = df2["Other adult correctional systems"].map(str) + df2["Unnamed: 1"].map(str)
df2["Other adult correctional systems"] = df2["Other adult correctional systems"].str.replace("nan", "").replace("NaN", "")
df2 = df2[df2.columns.drop(list(df2.filter(regex='Unnamed:')))]
df2.drop(df2.tail(5).index,inplace=True)

# Load in and clean third dataset
# I do not recommend we use this data, it is a bit hard to interpret - view excel file and you will see how it is difficult to load into pandas
# Dataset includes information on persons held in custody in state or federal prisons or in local jails, 2000, 2010, and 2015-2016

df3 = pd.read_csv('cpus16at03.csv', encoding ='latin1', skiprows=10, header=1)
df3["Persons in custody"] = df3["Persons in custody"].map(str) + df3["Unnamed: 1"].map(str)+df3["Unnamed: 2"].map(str)
df3["Persons in custody"] = df3["Persons in custody"].str.replace("nan", "").replace("NaN", "")
df3 = df3[df3.columns.drop(list(df3.filter(regex='Unnamed:')))]
df3.drop(df3.tail(9).index,inplace=True)
df3

# Load in and clean fourth dataset
# Dataset includes information on standard errors for local jail inmates at midyear, 2006-2016

df4 = pd.read_csv('cpus16at04.csv', encoding ='latin1', skiprows=9, header=1)
df4.drop(df4.tail(3).index,inplace=True)
df4

# Load in and clean fifth dataset
# This dataset includes Total population under
# the supervision of U.S. adult correctional systems, 2006-2016

df5 = pd.read_csv('cpus16f01.csv', encoding ='latin1', skiprows=10, header=1)
df5 = df5.rename(index=str, columns={"Unnamed: 0": "Year"})
df5.drop(df5.tail(2).index,inplace=True)
df5

# Load in and clean sixth dataset
# This dataset includes number of persons supervised
# by U.S. adult correctional systems, by correctional status, 2000 and 2006Ã±2016

df6 = pd.read_csv('cpus16t01.csv', encoding ='latin1', skiprows=10, header=1)
df6 = df6.rename(index=str, columns={"Unnamed: 1": "Month"})
df6["Year"][12] = '2016'
df6["Year"][13] = '2016'
df6 = df6[df6.columns.drop(list(df6.filter(regex='Unnamed:')))]
df6 = df6.drop(df6.index[11])
df6.drop(df6.tail(13).index,inplace=True)
df6 = df6.reset_index()
df6.loc[11][7] = 'NaN'
df6.loc[11][8] = 'NaN'
df6.loc[11][9] = 'NaN'
df6
